import streamlit as st
import os
import asyncio
from typing import List

# --- IMPORTACIONES DE LANGCHAIN Y GOOGLE ---
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_community.tools import WikipediaQueryRun
from langchain_community.utilities import WikipediaAPIWrapper
from langchain_community.callbacks import StreamlitCallbackHandler # <--- MEJORA VISUAL
from langchain_core.tools import tool, BaseTool
from langchain.agents import AgentExecutor, create_tool_calling_agent
from langchain_core.prompts import ChatPromptTemplate

# --- PARCHE PARA ASYNCIO EN STREAMLIT ---
# Soluciona el error "There is no current event loop"
try:
    asyncio.get_running_loop()
except RuntimeError:
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
# ----------------------------------------

# --- CONSTANTES ---
DOWNLOAD_DIR = "downloads"
MODEL_NAME = "gemini-2.0-flash"  # El modelo m谩s r谩pido y actual

st.set_page_config(page_title="Agente Investigador Gemini", page_icon="")
os.makedirs(DOWNLOAD_DIR, exist_ok=True)

# --- HERRAMIENTAS ---

@tool
def save_to_file(content: str, filename: str) -> str:
    """
    Guarda texto en un archivo local.
    Args:
        content: Texto a guardar.
        filename: Nombre del archivo (ej: 'resumen.txt').
    """
    try:
        safe_filename = os.path.basename(filename) or "resultado.txt"
        file_path = os.path.join(DOWNLOAD_DIR, safe_filename)
        with open(file_path, "w", encoding="utf-8") as f:
            f.write(content)
        return f"xito: Archivo guardado en {file_path}"
    except Exception as e:
        return f"Error al guardar: {str(e)}"

def get_tools() -> List[BaseTool]:
    api_wrapper = WikipediaAPIWrapper(top_k_results=1, doc_content_chars_max=2000)
    wiki_tool = WikipediaQueryRun(api_wrapper=api_wrapper)
    return [wiki_tool, save_to_file]

# --- INICIALIZACIN DEL AGENTE ---

@st.cache_resource(show_spinner="Conectando con Gemini...")
def init_agent(api_key: str):
    llm = ChatGoogleGenerativeAI(
        model=MODEL_NAME,
        google_api_key=api_key,
        temperature=0,
        max_output_tokens=8192
    )
    
    tools = get_tools()
    
    prompt = ChatPromptTemplate.from_messages([
        ("system", 
         "Eres un investigador experto. Tu misi贸n es: "
         "1. Buscar informaci贸n veraz en Wikipedia. "
         "2. Si el usuario lo pide, guardar un resumen usando 'save_to_file'. "
         "3. Ser conciso y profesional."),
        ("human", "{input}"),
        ("placeholder", "{agent_scratchpad}"),
    ])
    
    agent = create_tool_calling_agent(llm, tools, prompt)
    return AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)

# --- INTERFAZ PRINCIPAL ---

def main():
    st.title(" Agente: Wikipedia + Gemini 2.0")

    # Sidebar
    with st.sidebar:
        st.header("Configuraci贸n")
        google_api_key = st.text_input("Google AI Key", type="password")
        st.markdown("[Conseguir Key Gratis](https://aistudio.google.com/app/apikey)")
        if st.button("Limpiar Chat"):
            st.session_state.messages = []
            st.rerun()

    if not google_api_key:
        st.warning(" Por favor, introduce tu API Key para empezar.")
        return

    try:
        agent_executor = init_agent(google_api_key)
    except Exception as e:
        st.error(f"Error de conexi贸n: {e}")
        return

    # Historial
    if "messages" not in st.session_state:
        st.session_state.messages = []

    for msg in st.session_state.messages:
        with st.chat_message(msg["role"]):
            st.markdown(msg["content"])

    # Input Usuario
    if prompt_input := st.chat_input("Ej: Investiga sobre 'Nikola Tesla' y guarda un resumen"):
        st.session_state.messages.append({"role": "user", "content": prompt_input})
        with st.chat_message("user"):
            st.markdown(prompt_input)

        with st.chat_message("assistant"):
            try:
                # --- AQU EST LA MEJORA VISUAL ---
                # Esto muestra los pasos internos (Pensando -> Buscando -> Guardando)
                st_callback = StreamlitCallbackHandler(st.container())
                
                response = agent_executor.invoke(
                    {"input": prompt_input},
                    {"callbacks": [st_callback]}
                )
                # ----------------------------------
                
                output_text = response["output"]
                st.markdown(output_text)
                st.session_state.messages.append({"role": "assistant", "content": output_text})

                # Notificaci贸n de archivos
                if os.path.exists(DOWNLOAD_DIR) and os.listdir(DOWNLOAD_DIR):
                     # Solo mostramos mensaje si se menciona que se guard贸 algo recientemente
                    if "guardad" in output_text.lower():
                        st.success(f" Archivos disponibles en carpeta '{DOWNLOAD_DIR}'")

            except Exception as e:
                st.error(f"Ocurri贸 un error: {e}")

if __name__ == "__main__":
    main()